{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89b250af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: MaqCorre\n",
      "Processing: JobsCorre\n",
      "Processing: 1a100\n",
      "Processing: 100a120\n",
      "Processing: 100a200\n",
      "Processing: de10a100\n",
      "Processing: 1000a1100\n",
      "       file    id  makespan  integral_assignments  integral_percentage  \\\n",
      "0  1011.txt  1011      2581                   990                 99.0   \n",
      "1  1012.txt  1012      3578                   990                 99.0   \n",
      "2  1013.txt  1013      2090                   991                 99.1   \n",
      "3  1014.txt  1014      4386                   990                 99.0   \n",
      "4  1015.txt  1015      2730                   990                 99.0   \n",
      "\n",
      "   num_tasks  num_machines  time_seconds    cmax   dataset  \n",
      "0       1000            10        3.8792  2546.0  MaqCorre  \n",
      "1       1000            10        3.5508  3537.0  MaqCorre  \n",
      "2       1000            10        3.0524  2040.0  MaqCorre  \n",
      "3       1000            10        2.9084  4313.0  MaqCorre  \n",
      "4       1000            10        3.0528  2649.0  MaqCorre  \n",
      "    dataset      file  makespan    cmax  integral_percentage\n",
      "0  MaqCorre  1011.txt      2581  2546.0                 99.0\n",
      "1  MaqCorre  1012.txt      3578  3537.0                 99.0\n",
      "2  MaqCorre  1013.txt      2090  2040.0                 99.1\n",
      "3  MaqCorre  1014.txt      4386  4313.0                 99.0\n",
      "4  MaqCorre  1015.txt      2730  2649.0                 99.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------- PARSE BLOCK FILE --------------------\n",
    "def parse_results(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    blocks = content.strip().split('--------------------------------------------------------------------------------')\n",
    "    results = []\n",
    "\n",
    "    for block in blocks:\n",
    "        if not block.strip():\n",
    "            continue\n",
    "\n",
    "        data = {}\n",
    "        file_match = re.search(r'Plik:\\s*(\\S+)', block)\n",
    "        if file_match:\n",
    "            filename = file_match.group(1)\n",
    "            data['file'] = filename\n",
    "            data['id'] = int(re.search(r'\\d+', filename).group())  # extract number\n",
    "\n",
    "        makespan_match = re.search(r'Makespan:\\s*(\\d+)', block)\n",
    "        if makespan_match:\n",
    "            data['makespan'] = int(makespan_match.group(1))\n",
    "\n",
    "#         integral_match = re.search(r'Całkowitoliczbowe przypisania:\\s*(\\d+)\\s*\\(([\\d.]+)%\\)', block)\n",
    "#         if integral_match:\n",
    "#             data['integral_percentage'] = float(integral_match.group(2))\n",
    "\n",
    "        integral_match = re.search(r'Całkowitoliczbowe przypisania:\\s*(\\d+)\\s*\\(([\\d.]+)%\\)', block)\n",
    "        if integral_match:\n",
    "            data['integral_assignments'] = int(integral_match.group(1))\n",
    "            data['integral_percentage'] = float(integral_match.group(2))\n",
    "\n",
    "\n",
    "        tasks_match = re.search(r'Liczba zadań:\\s*(\\d+)', block)\n",
    "        if tasks_match:\n",
    "            data['num_tasks'] = int(tasks_match.group(1))\n",
    "\n",
    "        machines_match = re.search(r'Liczba maszyn:\\s*(\\d+)', block)\n",
    "        if machines_match:\n",
    "            data['num_machines'] = int(machines_match.group(1))\n",
    "\n",
    "        time_match = re.search(r'Czas działania \\(s\\):\\s*([\\d.]+)', block)\n",
    "        if time_match:\n",
    "            data['time_seconds'] = float(time_match.group(1))\n",
    "\n",
    "        results.append(data)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "# -------------------- PARSE CMAX FOLDER --------------------\n",
    "def extract_cmax_values(folder_path):\n",
    "    cmax_pattern = re.compile(r\"Cmax\\s+([\\d.]+)\")\n",
    "    file_id_pattern = re.compile(r'(\\d+)\\D')  # Extract numeric part before non-digit (e.g., \"1045CPLEX\")\n",
    "\n",
    "    cmax_records = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            match_id = file_id_pattern.match(filename)\n",
    "            if not match_id:\n",
    "                continue\n",
    "            file_id = int(match_id.group(1))\n",
    "\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                match_cmax = cmax_pattern.search(content)\n",
    "                if match_cmax:\n",
    "                    cmax_value = float(match_cmax.group(1))\n",
    "                    cmax_records.append({'id': file_id, 'cmax': cmax_value})\n",
    "\n",
    "    return pd.DataFrame(cmax_records)\n",
    "\n",
    "\n",
    "# -------------------- MAIN SCRIPT --------------------\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     # MaqCorre\n",
    "#     wyniki_file = \"wyniki_MaqCorre.txt\"\n",
    "#     cmax_folder = \"RCmax/TXT Cplex 2 horas log Maq Corre/\"\n",
    "    \n",
    "#     # JobsCorre\n",
    "#     wyniki_file = \"wyniki_JobsCorre.txt\"\n",
    "#     cmax_folder = \"RCmax/TXT Cplex 2 horas log Jobs Corre/\"\n",
    "     \n",
    "#     # 1a100\n",
    "#     wyniki_file = \"wyniki_1a100.txt\"\n",
    "#     cmax_folder = \"RCmax/TXT Cplex 2 horas log U(1,100)/txt Cplex 2 horas log/\"\n",
    "       \n",
    "#     # 100a120\n",
    "#     wyniki_file = \"wyniki_100a120.txt\"\n",
    "#     cmax_folder = \"RCmax/TXT Cplex 2 horas log U(100,120)/\"\n",
    "    \n",
    "#     # 100a200\n",
    "#     wyniki_file = \"wyniki_100a200.txt\n",
    "#     cmax_folder = \"RCmax/TXT Cplex 2 horas log U(100,200)/\"\n",
    "    \n",
    "#     # de10a100\n",
    "#     wyniki_file = \"wyniki_de10a100.txt\"\n",
    "#     cmax_folder = \"RCmax/TXT CPLEX 2 horas log U(10,100)/TXT CPLEX 2 horas de 10 a 100 log/\"\n",
    "    \n",
    "#     # Instanciasde1000a1100\n",
    "#     wyniki_file = \"wyniki_Instanciasde1000a1100.txt\"\n",
    "#     cmax_folder = \"RCmax/TXT Cplex 2 horas log U(1000,1100)/TXT Cplex 2 horas U(1000,1100)/\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Load parsed data\n",
    "#     df_results = parse_results(wyniki_file)\n",
    "#     df_cmax = extract_cmax_values(cmax_folder)\n",
    "\n",
    "    \n",
    "#     # Merge on 'id'\n",
    "#     df_merged = pd.merge(df_results, df_cmax, on=\"id\", how=\"left\")\n",
    "\n",
    "#     # Show results\n",
    "#     print(df_merged[['file', 'makespan', 'integral_percentage', 'cmax']])\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    datasets = {\n",
    "    \"MaqCorre\": (\"wyniki_MaqCorre.txt\", \"RCmax/TXT Cplex 2 horas log Maq Corre/\"),\n",
    "    \"JobsCorre\": (\"wyniki_JobsCorre.txt\", \"RCmax/TXT Cplex 2 horas log Jobs Corre/\"),\n",
    "    \"1a100\": (\"wyniki_1a100.txt\", \"RCmax/TXT Cplex 2 horas log U(1,100)/txt Cplex 2 horas log/\"),\n",
    "    \"100a120\": (\"wyniki_100a120.txt\", \"RCmax/TXT Cplex 2 horas log U(100,120)/\"),\n",
    "    \"100a200\": (\"wyniki_100a200.txt\", \"RCmax/TXT Cplex 2 horas log U(100,200)/\"),\n",
    "    \"de10a100\": (\"wyniki_de10a100.txt\", \"RCmax/TXT CPLEX 2 horas log U(10,100)/TXT CPLEX 2 horas de 10 a 100 log/\"),\n",
    "    \"1000a1100\": (\"wyniki_Instanciasde1000a1100.txt\", \"RCmax/TXT Cplex 2 horas log U(1000,1100)/TXT Cplex 2 horas U(1000,1100)/\")\n",
    "    }\n",
    "\n",
    "    df_dict = {}\n",
    "\n",
    "    for name, (wyniki_file, cmax_folder) in datasets.items():\n",
    "        print(f\"Processing: {name}\")\n",
    "        df_results = parse_results(wyniki_file)\n",
    "        df_cmax = extract_cmax_values(cmax_folder)\n",
    "        df_merged = pd.merge(df_results, df_cmax, on=\"id\", how=\"left\")\n",
    "        df_merged['dataset'] = name\n",
    "        df_dict[name] = df_merged\n",
    "\n",
    "    # Example: access MaqCorre dataframe\n",
    "    print(df_dict[\"MaqCorre\"].head())\n",
    "\n",
    "    # Optional: combine all into one DataFrame\n",
    "    df_all = pd.concat(df_dict.values(), ignore_index=True)\n",
    "    print(df_all[['dataset', 'file', 'makespan', 'cmax', 'integral_percentage']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8fc6e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Table:\n",
      "\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Average metrics across datasets}\n",
      "\\label{tab:average_metrics_across_datasets}\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      " & Makespan / Cmax & Time (s) & Integral % \\\\\n",
      "Dataset &  &  &  \\\\\n",
      "\\midrule\n",
      "MaqCorre & 1.236000 & 4.092000 & 89.688000 \\\\\n",
      "JobsCorre & 1.181000 & 4.413000 & 88.593000 \\\\\n",
      "1a100 & 1.353000 & 1.126000 & 92.211000 \\\\\n",
      "100a120 & 1.085000 & 5.089000 & 88.622000 \\\\\n",
      "100a200 & 1.088000 & 5.469000 & 87.898000 \\\\\n",
      "de10a100 & 1.146000 & 2.630000 & 88.509000 \\\\\n",
      "1000a1100 & 1.084000 & 12.059000 & 87.790000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "Minimum Table:\n",
      "\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Minimum metrics across datasets}\n",
      "\\label{tab:minimum_metrics_across_datasets}\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      " & Makespan / Cmax & Time (s) & Integral % \\\\\n",
      "Dataset &  &  &  \\\\\n",
      "\\midrule\n",
      "MaqCorre & 1.006000 & 0.128000 & 69.000000 \\\\\n",
      "JobsCorre & 1.009000 & 0.126000 & 60.000000 \\\\\n",
      "1a100 & 1.015000 & 0.063000 & 78.000000 \\\\\n",
      "100a120 & 1.002000 & 0.146000 & 59.000000 \\\\\n",
      "100a200 & 1.005000 & 0.097000 & 57.000000 \\\\\n",
      "de10a100 & 1.009000 & 0.090000 & 58.000000 \\\\\n",
      "1000a1100 & 0.999000 & 0.169000 & 57.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "Maximum Table:\n",
      "\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Maximum metrics across datasets}\n",
      "\\label{tab:maximum_metrics_across_datasets}\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      " & Makespan / Cmax & Time (s) & Integral % \\\\\n",
      "Dataset &  &  &  \\\\\n",
      "\\midrule\n",
      "MaqCorre & 1.873000 & 25.164000 & 99.100000 \\\\\n",
      "JobsCorre & 1.867000 & 26.014000 & 99.200000 \\\\\n",
      "1a100 & 1.923000 & 6.145000 & 99.200000 \\\\\n",
      "100a120 & 1.542000 & 29.230000 & 99.200000 \\\\\n",
      "100a200 & 1.491000 & 116.195000 & 99.000000 \\\\\n",
      "de10a100 & 1.633000 & 15.250000 & 99.200000 \\\\\n",
      "1000a1100 & 1.511000 & 245.010000 & 99.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "Approximation Table:\n",
      "\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Approximation ratios across datasets}\n",
      "\\label{tab:approximation_ratios_across_datasets}\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      " & min approx. & avg approx. & max approx. \\\\\n",
      "Dataset &  &  &  \\\\\n",
      "\\midrule\n",
      "MaqCorre & 1.006000 & 1.236000 & 1.873000 \\\\\n",
      "JobsCorre & 1.009000 & 1.181000 & 1.867000 \\\\\n",
      "1a100 & 1.015000 & 1.353000 & 1.923000 \\\\\n",
      "100a120 & 1.002000 & 1.085000 & 1.542000 \\\\\n",
      "100a200 & 1.005000 & 1.088000 & 1.491000 \\\\\n",
      "de10a100 & 1.009000 & 1.146000 & 1.633000 \\\\\n",
      "1000a1100 & 0.999000 & 1.084000 & 1.511000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize result tables\n",
    "avg_rows = []\n",
    "min_rows = []\n",
    "max_rows = []\n",
    "approx_rows = []\n",
    "for name, df in df_dict.items():\n",
    "    df = df.copy()\n",
    "    df['makespan_over_cmax'] = df['makespan'] / df['cmax']\n",
    "\n",
    "    avg_rows.append({\n",
    "        'Dataset': name,\n",
    "        'Makespan / Cmax': df['makespan_over_cmax'].mean(),\n",
    "        'Time (s)': df['time_seconds'].mean(),\n",
    "        'Integral %': df['integral_percentage'].mean()\n",
    "    })\n",
    "\n",
    "    min_rows.append({\n",
    "        'Dataset': name,\n",
    "        'Makespan / Cmax': df['makespan_over_cmax'].min(),\n",
    "        'Time (s)': df['time_seconds'].min(),\n",
    "        'Integral %': df['integral_percentage'].min()\n",
    "    })\n",
    "\n",
    "    max_rows.append({\n",
    "        'Dataset': name,\n",
    "        'Makespan / Cmax': df['makespan_over_cmax'].max(),\n",
    "        'Time (s)': df['time_seconds'].max(),\n",
    "        'Integral %': df['integral_percentage'].max()\n",
    "    })\n",
    "    \n",
    "    approx_rows.append({\n",
    "        'Dataset': name,\n",
    "        'min approx.': df['makespan_over_cmax'].min(),\n",
    "        'avg approx.': df['makespan_over_cmax'].mean(),\n",
    "        'max approx.': df['makespan_over_cmax'].max()\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames\n",
    "avg_df = pd.DataFrame(avg_rows).set_index('Dataset')\n",
    "min_df = pd.DataFrame(min_rows).set_index('Dataset')\n",
    "max_df = pd.DataFrame(max_rows).set_index('Dataset')\n",
    "approx_df = pd.DataFrame(approx_rows).set_index('Dataset')\n",
    "\n",
    "# Format and export LaTeX\n",
    "def format_latex_table(df, caption):\n",
    "    return df.round(3).to_latex(\n",
    "        caption=caption,\n",
    "        label=f\"tab:{caption.lower().replace(' ', '_')}\",\n",
    "        position='htbp',\n",
    "        column_format='lccc',\n",
    "        escape=False\n",
    "    )\n",
    "\n",
    "print(\"Average Table:\\n\")\n",
    "print(format_latex_table(avg_df, \"Average metrics across datasets\"))\n",
    "\n",
    "print(\"\\nMinimum Table:\\n\")\n",
    "print(format_latex_table(min_df, \"Minimum metrics across datasets\"))\n",
    "\n",
    "print(\"\\nMaximum Table:\\n\")\n",
    "print(format_latex_table(max_df, \"Maximum metrics across datasets\"))\n",
    "\n",
    "print(\"\\nApproximation Table:\\n\")\n",
    "print(format_latex_table(approx_df, \"Approximation ratios across datasets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6932b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d494cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94281692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset: MaqCorre ===\n",
      "  No instances where MAKESPAN < CMAX.\n",
      "  No instances where MAKESPAN > 2 * CMAX.\n",
      "\n",
      "=== Dataset: JobsCorre ===\n",
      "  No instances where MAKESPAN < CMAX.\n",
      "  No instances where MAKESPAN > 2 * CMAX.\n",
      "\n",
      "=== Dataset: 1a100 ===\n",
      "  No instances where MAKESPAN < CMAX.\n",
      "  No instances where MAKESPAN > 2 * CMAX.\n",
      "\n",
      "=== Dataset: 100a120 ===\n",
      "  No instances where MAKESPAN < CMAX.\n",
      "  No instances where MAKESPAN > 2 * CMAX.\n",
      "\n",
      "=== Dataset: 100a200 ===\n",
      "  No instances where MAKESPAN < CMAX.\n",
      "  No instances where MAKESPAN > 2 * CMAX.\n",
      "\n",
      "=== Dataset: de10a100 ===\n",
      "  No instances where MAKESPAN < CMAX.\n",
      "  No instances where MAKESPAN > 2 * CMAX.\n",
      "\n",
      "=== Dataset: 1000a1100 ===\n",
      "  MAKESPAN < CMAX:\n",
      "      id     file  makespan    cmax\n",
      "124  235  235.txt      7037  7039.0\n",
      "128  239  239.txt      7034  7038.0\n",
      "  No instances where MAKESPAN > 2 * CMAX.\n"
     ]
    }
   ],
   "source": [
    "for name, df in df_dict.items():\n",
    "    print(f\"\\n=== Dataset: {name} ===\")\n",
    "\n",
    "    # Rows where makespan < cmax\n",
    "    lower_than_cmax = df[df[\"makespan\"] < df[\"cmax\"]]\n",
    "    if not lower_than_cmax.empty:\n",
    "        print(\"  MAKESPAN < CMAX:\")\n",
    "        print(lower_than_cmax[[\"id\", \"file\", \"makespan\", \"cmax\"]])\n",
    "    else:\n",
    "        print(\"  No instances where MAKESPAN < CMAX.\")\n",
    "\n",
    "    # Rows where makespan > 2 * cmax\n",
    "    greater_than_2cmax = df[df[\"makespan\"] > 2 * df[\"cmax\"]]\n",
    "    if not greater_than_2cmax.empty:\n",
    "        print(\"  MAKESPAN > 2 * CMAX:\")\n",
    "        print(greater_than_2cmax[[\"id\", \"file\", \"makespan\", \"cmax\"]])\n",
    "    else:\n",
    "        print(\"  No instances where MAKESPAN > 2 * CMAX.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4f85b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rows where makespan < cmax\n",
    "# lower_than_cmax = df_merged[df_merged[\"makespan\"] < df_merged[\"cmax\"]]\n",
    "# print(\"=== MAKESPAN < CMAX ===\")\n",
    "# print(lower_than_cmax[[\"id\", \"file\", \"makespan\", \"cmax\"]])\n",
    "\n",
    "# # Rows where makespan > 2 * cmax\n",
    "# greater_than_2cmax = df_merged[df_merged[\"makespan\"] > 2 * df_merged[\"cmax\"]]\n",
    "# print(\"\\n=== MAKESPAN > 2 * CMAX ===\")\n",
    "# print(greater_than_2cmax[[\"id\", \"file\", \"makespan\", \"cmax\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "365e4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Prepare instance names\n",
    "# df_merged['instance'] = df_merged['file'].str.replace('.txt', '', regex=False)\n",
    "\n",
    "# # Sort by id (optional, helps consistent plotting)\n",
    "# df_merged = df_merged.sort_values('id')\n",
    "\n",
    "# # Plot 1: Makespan / Cmax\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# sns.scatterplot(x='instance', y=df_merged['makespan'] / df_merged['cmax'], data=df_merged, marker='o')\n",
    "# plt.axhline(2.0, color='red', linestyle='--', label='2.0 threshold')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.ylabel('Makespan / Cmax')\n",
    "# plt.title('Relative Makespan per Instance')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "156c4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot 2: Time in seconds\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# sns.barplot(x='instance', y='time_seconds', data=df_merged)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.ylabel('Time (s)')\n",
    "# plt.title('Execution Time per Instance')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f4803b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Plot 3: Integral assignment percentage\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# sns.barplot(x='instance', y='integral_percentage', data=df_merged)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.ylabel('Integral Assignment (%)')\n",
    "# plt.title('Integral Assignment Percentage per Instance')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "81d1f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting for: MaqCorre\n",
      "Saved to plots_MaqCorre.pdf\n",
      "Plotting for: JobsCorre\n",
      "Saved to plots_JobsCorre.pdf\n",
      "Plotting for: 1a100\n",
      "Saved to plots_1a100.pdf\n",
      "Plotting for: 100a120\n",
      "Saved to plots_100a120.pdf\n",
      "Plotting for: 100a200\n",
      "Saved to plots_100a200.pdf\n",
      "Plotting for: de10a100\n",
      "Saved to plots_de10a100.pdf\n",
      "Plotting for: 1000a1100\n",
      "Saved to plots_1000a1100.pdf\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for name, df in df_dict.items():\n",
    "    print(f\"Plotting for: {name}\")\n",
    "    df = df.copy()\n",
    "    df['instance'] = df['file'].str.replace('.txt', '', regex=False)\n",
    "    df = df.sort_values('id')\n",
    "\n",
    "    pdf_filename = f\"plots_{name}.pdf\"\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "\n",
    "        # Plot 1: Makespan / Cmax\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        sns.scatterplot(x='instance', y=df['makespan'] / df['cmax'], data=df, marker='o')\n",
    "        plt.axhline(2.0, color='red', linestyle='--', label='2.0 threshold')\n",
    "        xticks = df['instance'].tolist()\n",
    "        step = max(1, len(xticks) // 20)  # Show at most ~20 labels\n",
    "        plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)        \n",
    "        plt.ylabel('Makespan / Cmax')\n",
    "        plt.title(f'Relative Makespan per Instance: {name}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        # Plot 2: Time in seconds\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        sns.barplot(x='instance', y='time_seconds', data=df)\n",
    "        xticks = df['instance'].tolist()\n",
    "        step = max(1, len(xticks) // 20)  # Show at most ~20 labels\n",
    "        plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)\n",
    "        plt.ylabel('Time (s)')\n",
    "        plt.title(f'Execution Time per Instance: {name}')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        # Plot 3: Integral assignment percentage\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        sns.barplot(x='instance', y='integral_percentage', data=df)\n",
    "        xticks = df['instance'].tolist()\n",
    "        step = max(1, len(xticks) // 20)  # Show at most ~20 labels\n",
    "        plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)\n",
    "        plt.ylabel('Integral Assignment (%)')\n",
    "        plt.title(f'Integral Assignment Percentage per Instance: {name}')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 4: Number of integral assignments (scatter)\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        sns.scatterplot(x='instance', y='integral_assignments', data=df, marker='o', s=60)\n",
    "        xticks = df['instance'].tolist()\n",
    "        step = max(1, len(xticks) // 20)  # Show at most ~20 labels\n",
    "        plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)\n",
    "        plt.ylabel('Number of Integral Assignments')\n",
    "        plt.title(f'Integral Assignments per Instance: {name}')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Saved to {pdf_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5a5c8788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting for: MaqCorre\n",
      "Saved plots to folder: plots/MaqCorre\n",
      "Plotting for: JobsCorre\n",
      "Saved plots to folder: plots/JobsCorre\n",
      "Plotting for: 1a100\n",
      "Saved plots to folder: plots/1a100\n",
      "Plotting for: 100a120\n",
      "Saved plots to folder: plots/100a120\n",
      "Plotting for: 100a200\n",
      "Saved plots to folder: plots/100a200\n",
      "Plotting for: de10a100\n",
      "Saved plots to folder: plots/de10a100\n",
      "Plotting for: 1000a1100\n",
      "Saved plots to folder: plots/1000a1100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for name, df in df_dict.items():\n",
    "  print(f\"Plotting for: {name}\")\n",
    "  df = df.copy()\n",
    "  df['instance'] = df['file'].str.replace('.txt', '', regex=False)\n",
    "  df = df.sort_values('id')\n",
    "  xticks = df['instance'].tolist()\n",
    "  step = max(1, len(xticks) // 20)\n",
    "\n",
    "  # Create output folder\n",
    "  output_dir = os.path.join(\"plots\", name)\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  # Plot 1: Makespan / Cmax\n",
    "  with PdfPages(os.path.join(output_dir, \"makespan_cmax.pdf\")) as pdf:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    sns.scatterplot(x='instance', y=df['makespan'] / df['cmax'], data=df, marker='o')\n",
    "    plt.axhline(2.0, color='red', linestyle='--', label='2.0 threshold')\n",
    "    plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)\n",
    "    plt.ylabel('Makespan / Cmax')\n",
    "    plt.title(f'Relative Makespan per Instance: {name}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "  # Plot 2: Time in seconds\n",
    "  with PdfPages(os.path.join(output_dir, \"execution_time.pdf\")) as pdf:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    sns.barplot(x='instance', y='time_seconds', data=df)\n",
    "    plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.title(f'Execution Time per Instance: {name}')\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "  # Plot 3: Integral assignment percentage\n",
    "  with PdfPages(os.path.join(output_dir, \"integral_percentage.pdf\")) as pdf:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    sns.barplot(x='instance', y='integral_percentage', data=df)\n",
    "    plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)\n",
    "    plt.ylabel('Integral Assignment (%)')\n",
    "    plt.title(f'Integral Assignment Percentage per Instance: {name}')\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "  # Plot 4: Number of integral assignments\n",
    "  with PdfPages(os.path.join(output_dir, \"integral_assignments.pdf\")) as pdf:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    sns.scatterplot(x='instance', y='integral_assignments', data=df, marker='o', s=60)\n",
    "    plt.xticks(ticks=range(0, len(xticks), step), labels=xticks[::step], rotation=90)\n",
    "    plt.ylabel('Number of Integral Assignments')\n",
    "    plt.title(f'Integral Assignments per Instance: {name}')\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "  print(f\"Saved plots to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5a9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae0225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572025ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc45e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
